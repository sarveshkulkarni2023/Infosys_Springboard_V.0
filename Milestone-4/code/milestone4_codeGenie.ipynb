{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxXqYqQ7o+dzk8dnQ08wSZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DineshGujjeti/Infosys_Springboard_CodeGenie/blob/main/Milestone4/code/milestone4_codeGenie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlM1bXGIKesh",
        "outputId": "c8e9b75f-3ad4-4285-a2b6-a72b715da6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing all required packages...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.2\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.12/dist-packages (2.10.1)\n",
            "Collecting bcrypt\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (0.21)\n",
            "Collecting plotly-express\n",
            "  Downloading plotly_express-0.4.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n",
            "Collecting streamlit-autorefresh\n",
            "  Downloading streamlit_autorefresh-1.0.1-py3-none-any.whl.metadata (436 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from plotly-express) (5.24.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from plotly-express) (0.14.5)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.12/dist-packages (from plotly-express) (1.16.3)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.12/dist-packages (from plotly-express) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "Downloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
            "Downloading streamlit_autorefresh-1.0.1-py3-none-any.whl (700 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m700.8/700.8 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, bcrypt, pydeck, plotly-express, streamlit, streamlit-autorefresh\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6/6\u001b[0m [streamlit-autorefresh]\n",
            "\u001b[1A\u001b[2KSuccessfully installed bcrypt-5.0.0 plotly-express-0.4.1 pydeck-0.9.1 pyngrok-7.4.1 streamlit-1.51.0 streamlit-autorefresh-1.0.1\n",
            "‚úÖ All dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install Dependencies (Final)\n",
        "print(\"üì¶ Installing all required packages...\")\n",
        "\n",
        "# Set up environment variables from Colab Secrets\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['JWT_SECRET_KEY'] = userdata.get('JWT_SECRET_KEY')\n",
        "os.environ['NGROK_TOKEN'] = userdata.get('NGROK_TOKEN')\n",
        "\n",
        "# Install all required packages\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# PyTorch\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Transformers, Accelerate, and BitsAndBytes for 4-bit loading\n",
        "!pip install transformers accelerate bitsandbytes\n",
        "\n",
        "# Streamlit and utilities (radon removed)\n",
        "!pip install streamlit pyngrok PyJWT bcrypt pandas graphviz plotly-express psutil streamlit-autorefresh numpy\n",
        "\n",
        "print(\"‚úÖ All dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import sqlite3\n",
        "import bcrypt\n",
        "import jwt\n",
        "import os\n",
        "import graphviz\n",
        "import ast\n",
        "import torch\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import time\n",
        "import gc # Garbage Collector\n",
        "import psutil # For system stats\n",
        "import json # For copy-to-clipboard\n",
        "import numpy as np # For network graph\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from datetime import datetime, timedelta\n",
        "from streamlit_autorefresh import st_autorefresh # For live updates\n",
        "\n",
        "# --- 1. CONFIGURATION & SECRETS ---\n",
        "\n",
        "HF_TOKEN = os.environ.get('HF_TOKEN')\n",
        "JWT_SECRET = os.environ.get('JWT_SECRET_KEY', \"dummy_jwt\")\n",
        "NGROK_TOKEN = os.environ.get('NGROK_TOKEN', \"dummy_ngrok\")\n",
        "\n",
        "DB_NAME = \"users.db\"\n",
        "\n",
        "# --- 2. DATABASE UTILITIES ---\n",
        "\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS users (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        username TEXT UNIQUE NOT NULL,\n",
        "        password_hash TEXT NOT NULL,\n",
        "        security_question TEXT NOT NULL,\n",
        "        security_answer_hash TEXT NOT NULL,\n",
        "        role TEXT NOT NULL DEFAULT 'user'\n",
        "    )\n",
        "    ''')\n",
        "    c.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS activity_log (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        user_id INTEGER,\n",
        "        timestamp TEXT NOT NULL,\n",
        "        prompt TEXT NOT NULL,\n",
        "        model_name TEXT NOT NULL,\n",
        "        language TEXT NOT NULL,\n",
        "        response_time REAL,\n",
        "        feedback_score INTEGER DEFAULT 0,\n",
        "        feedback_comment TEXT\n",
        "    )\n",
        "    ''')\n",
        "    c.execute(\"SELECT COUNT(*) FROM users\")\n",
        "    user_count = c.fetchone()[0]\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return user_count == 0\n",
        "\n",
        "def hash_text(text):\n",
        "    salt = bcrypt.gensalt()\n",
        "    return bcrypt.hashpw(text.encode('utf-8'), salt)\n",
        "\n",
        "def check_hash(text, hashed):\n",
        "    return bcrypt.checkpw(text.encode('utf-8'), hashed)\n",
        "\n",
        "def add_user(username, password, question, answer, role='user'):\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        password_hash = hash_text(password)\n",
        "        answer_hash = hash_text(answer)\n",
        "        c.execute(\n",
        "            \"INSERT INTO users (username, password_hash, security_question, security_answer_hash, role) VALUES (?, ?, ?, ?, ?)\",\n",
        "            (username, password_hash, question, answer_hash, role)\n",
        "        )\n",
        "        conn.commit()\n",
        "        return True\n",
        "    except sqlite3.IntegrityError:\n",
        "        return False\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "def verify_user(username, password):\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT password_hash, role FROM users WHERE username=?\", (username,))\n",
        "    user = c.fetchone()\n",
        "    conn.close()\n",
        "    if user:\n",
        "        password_hash, role = user\n",
        "        if check_hash(password, password_hash):\n",
        "            return {\"username\": username, \"role\": role}\n",
        "    return None\n",
        "\n",
        "def update_user_password(username, new_password):\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    new_password_hash = hash_text(new_password)\n",
        "    c.execute(\"UPDATE users SET password_hash = ? WHERE username = ?\", (new_password_hash, username))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def get_all_users():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT id, username, role FROM users\")\n",
        "    users = c.fetchall()\n",
        "    conn.close()\n",
        "    return users\n",
        "\n",
        "def get_user_details(username):\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT username, security_question, security_answer_hash FROM users WHERE username=?\", (username,))\n",
        "    user = c.fetchone()\n",
        "    conn.close()\n",
        "    if user:\n",
        "        return {\"username\": user[0], \"question\": user[1], \"answer_hash\": user[2]}\n",
        "    return None\n",
        "\n",
        "# --- LOGGING AND QUERY FUNCTIONS ---\n",
        "\n",
        "# --- THIS IS THE FIX ---\n",
        "def log_user_activity(username, prompt, model_name, language, response_time):\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT id FROM users WHERE username=?\", (username,))\n",
        "        user_id = c.fetchone()\n",
        "        if user_id:\n",
        "            user_id = user_id[0]\n",
        "        else:\n",
        "            return\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        c.execute(\n",
        "            \"INSERT INTO activity_log (user_id, timestamp, prompt, model_name, language, response_time) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (user_id, timestamp, prompt, model_name, language, response_time)\n",
        "        )\n",
        "        # --- END FIX ---\n",
        "        conn.commit()\n",
        "        c.execute(\"SELECT last_insert_rowid()\")\n",
        "        st.session_state['last_activity_id'] = c.fetchone()[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error logging activity to DB: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def update_feedback_score(activity_id, score, comment):\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE activity_log SET feedback_score = ?, feedback_comment = ? WHERE id = ?\", (score, comment, activity_id))\n",
        "        conn.commit()\n",
        "\n",
        "        add_system_log(f\"Feedback (ID: {activity_id}): {score}‚≠ê - '{comment}'\", \"üí¨\")\n",
        "\n",
        "        if 'last_activity_id' in st.session_state:\n",
        "            del st.session_state['last_activity_id']\n",
        "        st.toast(f\"Feedback submitted! Thank you.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to submit feedback: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- DASHBOARD QUERY FUNCTIONS ---\n",
        "def get_total_users():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT COUNT(id) FROM users\")\n",
        "    count = c.fetchone()[0]\n",
        "    conn.close()\n",
        "    return count\n",
        "\n",
        "def get_total_queries():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT COUNT(id) FROM activity_log\")\n",
        "    count = c.fetchone()[0]\n",
        "    conn.close()\n",
        "    return count\n",
        "\n",
        "def get_average_latency():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT AVG(response_time) FROM activity_log\")\n",
        "    avg_latency = c.fetchone()[0]\n",
        "    conn.close()\n",
        "    return f\"{avg_latency:.1f}\" if avg_latency is not None else \"0.0\"\n",
        "\n",
        "def get_trending_queries():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"\"\"\n",
        "        SELECT prompt, COUNT(prompt) as count\n",
        "        FROM activity_log\n",
        "        GROUP BY prompt\n",
        "        ORDER BY count DESC\n",
        "        LIMIT 5\n",
        "    \"\"\")\n",
        "    data = c.fetchall()\n",
        "    conn.close()\n",
        "    trending_data = [\n",
        "        {'Query': (row[0][:40] + '...') if len(row[0]) > 40 else row[0], 'Count': row[1]}\n",
        "        for row in data\n",
        "    ]\n",
        "    trending_data = pd.DataFrame(trending_data)\n",
        "    return trending_data\n",
        "\n",
        "def get_language_usage():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"\"\"\n",
        "        SELECT language, COUNT(language) as count\n",
        "        FROM activity_log\n",
        "        GROUP BY language\n",
        "    \"\"\")\n",
        "    data = c.fetchall()\n",
        "    conn.close()\n",
        "    df = pd.DataFrame(data, columns=['Language', 'Count'])\n",
        "    if df.empty:\n",
        "        return pd.DataFrame({'Language': ['None'], 'Count': [0]})\n",
        "    df = df.sort_values(by='Count', ascending=False)\n",
        "    return df\n",
        "\n",
        "def get_positive_feedback_rate():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT COUNT(id) FROM activity_log WHERE feedback_score != 0\")\n",
        "    total_feedback = c.fetchone()[0]\n",
        "    if total_feedback == 0:\n",
        "        conn.close()\n",
        "        return \"N/A\", None\n",
        "    c.execute(\"SELECT COUNT(id) FROM activity_log WHERE feedback_score > 3\") # 4 or 5 stars\n",
        "    positive_feedback = c.fetchone()[0]\n",
        "    rate = (positive_feedback / total_feedback) * 100\n",
        "    conn.close()\n",
        "    return f\"{rate:.0f}%\", None\n",
        "\n",
        "def get_user_history(username):\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT id FROM users WHERE username=?\", (username,))\n",
        "    user_id = c.fetchone()[0]\n",
        "    c.execute(\"\"\"\n",
        "        SELECT timestamp, model_name, language, prompt, response_time, feedback_score\n",
        "        FROM activity_log\n",
        "        WHERE user_id = ?\n",
        "        ORDER BY timestamp DESC\n",
        "        LIMIT 10\n",
        "    \"\"\", (user_id,))\n",
        "    data = c.fetchall()\n",
        "    conn.close()\n",
        "    history = pd.DataFrame(data, columns=['Timestamp', 'Model', 'Lang', 'Prompt', 'Latency (s)', 'Feedback'])\n",
        "    history['Latency (s)'] = history['Latency (s)'].round(2)\n",
        "    history['Feedback'] = history['Feedback'].map(lambda x: \"‚≠ê\" * x if x > 0 else \"‚Äî\")\n",
        "    return history\n",
        "\n",
        "def get_full_history():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    history_df = pd.read_sql_query(\"SELECT * FROM activity_log ORDER BY timestamp DESC LIMIT 20\", conn)\n",
        "    conn.close()\n",
        "    return history_df\n",
        "\n",
        "def get_full_feedback():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        a.timestamp,\n",
        "        u.username,\n",
        "        a.prompt,\n",
        "        a.model_name,\n",
        "        a.feedback_score,\n",
        "        a.feedback_comment\n",
        "    FROM activity_log a\n",
        "    JOIN users u ON a.user_id = u.id\n",
        "    WHERE a.feedback_score > 0\n",
        "    ORDER BY a.timestamp DESC\n",
        "    LIMIT 10\n",
        "    \"\"\"\n",
        "    feedback_df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    feedback_df['Feedback'] = feedback_df['feedback_score'].map(lambda x: \"‚≠ê\" * x)\n",
        "    return feedback_df[['timestamp', 'username', 'prompt', 'Feedback', 'feedback_comment']]\n",
        "\n",
        "\n",
        "# --- 3. AUTHENTICATION (JWT) ---\n",
        "\n",
        "def create_jwt(username, role):\n",
        "    payload = {\n",
        "        'sub': username,\n",
        "        'role': role,\n",
        "        'iat': datetime.utcnow(),\n",
        "        'exp': datetime.utcnow() + timedelta(hours=24)\n",
        "    }\n",
        "    token = jwt.encode(payload, JWT_SECRET, algorithm='HS256')\n",
        "    return token\n",
        "\n",
        "def verify_jwt(token):\n",
        "    try:\n",
        "        payload = jwt.decode(token, JWT_SECRET, algorithms=['HS256'])\n",
        "        return payload\n",
        "    except jwt.ExpiredSignatureError:\n",
        "        st.error(\"Session expired. Please log in again.\")\n",
        "        return None\n",
        "    except jwt.InvalidTokenError:\n",
        "        st.error(\"Invalid token. Please log in again.\")\n",
        "        return None\n",
        "\n",
        "# --- 4. DYNAMIC MODEL LOADING (MEMORY EFFICIENT) ---\n",
        "\n",
        "MODELS = {\n",
        "    \"Gemma-2B-IT\": \"google/gemma-2b-it\",\n",
        "    \"DeepSeek-Coder-1.3B\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
        "    \"Phi-2\": \"microsoft/phi-2\"\n",
        "}\n",
        "\n",
        "def load_model_from_hub(model_path):\n",
        "    token = os.environ.get('HF_TOKEN')\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, token=token)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        trust_remote_code=True,\n",
        "        token=token\n",
        "    )\n",
        "    return model, tokenizer\n",
        "\n",
        "def get_model_and_tokenizer(model_name_key):\n",
        "    model_path = MODELS.get(model_name_key)\n",
        "    if not model_path:\n",
        "        st.error(f\"Model key {model_name_key} not found in MODELS dict.\")\n",
        "        return None, None\n",
        "\n",
        "    if st.session_state.get('loaded_model_name') != model_path:\n",
        "        if 'loaded_model' in st.session_state:\n",
        "            log_msg = f\"Unloading old model: {st.session_state.loaded_model_name}\"\n",
        "            print(log_msg)\n",
        "            add_system_log(log_msg, \"‚ôªÔ∏è\")\n",
        "            del st.session_state.loaded_model\n",
        "            del st.session_state.loaded_tokenizer\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"Old model unloaded.\")\n",
        "\n",
        "        log_msg = f\"Loading new model: {model_path}...\"\n",
        "        print(log_msg)\n",
        "        add_system_log(log_msg, \"‚è≥\")\n",
        "\n",
        "        with st.spinner(f\"Loading {model_name_key}... (This may take a moment)\"):\n",
        "            try:\n",
        "                start_load = time.time()\n",
        "                model, tokenizer = load_model_from_hub(model_path)\n",
        "                load_time = time.time() - start_load\n",
        "            except Exception as e:\n",
        "                st.error(f\"Failed to load model {model_path}: {e}\")\n",
        "                if 'loaded_model_name' in st.session_state: del st.session_state.loaded_model_name\n",
        "                return None, None\n",
        "\n",
        "        st.session_state.loaded_model_name = model_path\n",
        "        st.session_state.loaded_model = model\n",
        "        st.session_state.loaded_tokenizer = tokenizer\n",
        "        st.session_state.model_load_time = load_time\n",
        "        log_msg = f\"Model {model_name_key} loaded in {load_time:.2f}s.\"\n",
        "        print(log_msg)\n",
        "        add_system_log(log_msg, \"‚úÖ\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Using cached model: {model_path}\")\n",
        "\n",
        "    return st.session_state.loaded_model, st.session_state.loaded_tokenizer\n",
        "\n",
        "def generate_code(prompt, model_name_key):\n",
        "    model, tokenizer = get_model_and_tokenizer(model_name_key)\n",
        "    if model is None:\n",
        "        return f\"Error: Model {model_name_key} failed to load.\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    attention_mask = inputs.attention_mask\n",
        "    output_ids = model.generate(\n",
        "        inputs.input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.1,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    response_tokens = output_ids[0][inputs.input_ids.shape[-1]:]\n",
        "    code = tokenizer.decode(response_tokens, skip_special_tokens=True)\n",
        "\n",
        "    if not code or not code.strip() or \"undefined\" in code:\n",
        "        return \"```\\nError: Model returned an empty or invalid response. Please try again.\\n```\"\n",
        "\n",
        "    formatted_code = f\"```python\\n{code.strip()}\\n```\"\n",
        "    return formatted_code\n",
        "\n",
        "def query_hf_model(payload, model_name_key):\n",
        "    try:\n",
        "        formatted_code = generate_code(payload, model_name_key)\n",
        "        return formatted_code\n",
        "    except Exception as e:\n",
        "        return f\"Error: Code Generation/Explanation failed: {str(e)}\"\n",
        "\n",
        "# --- 5. AST VISUALIZER ---\n",
        "\n",
        "class ASTVisualizer:\n",
        "    def __init__(self):\n",
        "        self.graph = graphviz.Digraph(comment='Python AST', graph_attr={'rankdir': 'TB', 'bgcolor': '#333333'}, node_attr={'style': 'filled', 'color': '#FF6347', 'fontcolor': 'white', 'fillcolor': '#444444'})\n",
        "\n",
        "    def traverse(self, node, parent_id=None):\n",
        "        node_id = str(id(node))\n",
        "        node_label = type(node).__name__\n",
        "        if hasattr(node, 'id') and isinstance(node.id, str):\n",
        "            node_label = f\"Name\\n(id='{node.id}')\"\n",
        "        elif isinstance(node, ast.Constant):\n",
        "            node_label = f\"Constant\\n(value={repr(node.value)})\"\n",
        "        elif isinstance(node, ast.Attribute):\n",
        "            node_label = f\"Attribute\\n(attr='{node.attr}')\"\n",
        "        elif isinstance(node, ast.FunctionDef):\n",
        "            node_label = f\"FunctionDef\\n(name='{node.name}')\"\n",
        "        self.graph.node(node_id, label=node_label)\n",
        "        if parent_id:\n",
        "            self.graph.edge(parent_id, node_id)\n",
        "        for field, value in ast.iter_fields(node):\n",
        "            if isinstance(value, list):\n",
        "                for item in value:\n",
        "                    if isinstance(item, ast.AST):\n",
        "                        self.traverse(item, node_id)\n",
        "            elif isinstance(value, ast.AST):\n",
        "                self.traverse(value, node_id)\n",
        "\n",
        "    def get_graph(self, code):\n",
        "        try:\n",
        "            tree = ast.parse(code)\n",
        "            self.traverse(tree)\n",
        "            return self.graph\n",
        "        except SyntaxError as e:\n",
        "            st.error(f\"Python Syntax Error: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error building AST: {e}\")\n",
        "            return None\n",
        "\n",
        "# --- 6. STREAMLIT APP UI ---\n",
        "\n",
        "def add_system_log(message, icon=\"‚öôÔ∏è\"):\n",
        "    \"\"\"Adds a new log to the session state log list.\"\"\"\n",
        "    if 'system_logs' not in st.session_state:\n",
        "        st.session_state.system_logs = []\n",
        "    log_entry = f\"{icon} {datetime.now().strftime('%H:%M:%S')} - {message}\"\n",
        "    st.session_state.system_logs.insert(0, log_entry)\n",
        "    st.session_state.system_logs = st.session_state.system_logs[:50]\n",
        "\n",
        "def initialize_state():\n",
        "    # Base state\n",
        "    if \"logged_in\" not in st.session_state: st.session_state.logged_in = False\n",
        "    if \"username\" not in st.session_state: st.session_state.username = None\n",
        "    if \"role\" not in st.session_state: st.session_state.role = None\n",
        "    if \"page\" not in st.session_state: st.session_state.page = \"Login\"\n",
        "    if \"token\" not in st.session_state: st.session_state.token = None\n",
        "    if \"chat_history\" not in st.session_state: st.session_state.chat_history = []\n",
        "    if \"last_output\" not in st.session_state: st.session_state.last_output = \"\"\n",
        "    if \"last_activity_id\" not in st.session_state: st.session_state.last_activity_id = None\n",
        "    if \"reset_step\" not in st.session_state: st.session_state.reset_step = 1\n",
        "    if \"reset_user\" not in st.session_state: st.session_state.reset_user = None\n",
        "\n",
        "    # DYNAMIC MODEL LOADING STATE\n",
        "    if 'loaded_model_name' not in st.session_state: st.session_state.loaded_model_name = None\n",
        "    if 'loaded_model' not in st.session_state: st.session_state.loaded_model = None\n",
        "    if 'loaded_tokenizer' not in st.session_state: st.session_state.loaded_tokenizer = None\n",
        "    if 'model_load_time' not in st.session_state: st.session_state.model_load_time = 0.0\n",
        "\n",
        "    # Explainer state\n",
        "    if 'explanation' not in st.session_state: st.session_state.explanation = \"\"\n",
        "    if 'ast_graph' not in st.session_state: st.session_state.ast_graph = None\n",
        "\n",
        "    # --- NEW ADMIN DASHBOARD STATE ---\n",
        "    if 'admin_boot_animation_done' not in st.session_state: st.session_state.admin_boot_animation_done = False\n",
        "    if 'gpu_history' not in st.session_state: st.session_state.gpu_history = [] # For live charts\n",
        "    if 'network_history' not in st.session_state: st.session_state.network_history = [] # For live charts\n",
        "    if 'system_logs' not in st.session_state: st.session_state.system_logs = []\n",
        "    if 'exp_torch_compile' not in st.session_state: st.session_state.exp_torch_compile = False\n",
        "    if 'exp_mixed_precision' not in st.session_state: st.session_state.exp_mixed_precision = True\n",
        "    if 'reveal_keys' not in st.session_state: st.session_state.reveal_keys = False\n",
        "\n",
        "\n",
        "def show_login_page(is_first_user):\n",
        "    st.title(\"CodeGenie üßû\")\n",
        "    col1, col2 = st.columns([2, 3])\n",
        "    with col1:\n",
        "        st.subheader(\"Welcome Back\")\n",
        "    with col2:\n",
        "        with st.container(border=True):\n",
        "            tab1, tab2 = st.tabs([\"Login\", \"Sign Up\"])\n",
        "            with tab1:\n",
        "                with st.form(\"login_form\"):\n",
        "                    username = st.text_input(\"Username\", key=\"login_username\")\n",
        "                    password = st.text_input(\"Password\", type=\"password\", key=\"login_password\")\n",
        "                    login_button = st.form_submit_button(\"Login\", use_container_width=True)\n",
        "                    if login_button:\n",
        "                        user_data = verify_user(username, password)\n",
        "                        if user_data:\n",
        "                            st.session_state.logged_in = True\n",
        "                            st.session_state.username = user_data[\"username\"]\n",
        "                            st.session_state.role = user_data[\"role\"]\n",
        "                            st.session_state.token = create_jwt(user_data[\"username\"], user_data[\"role\"])\n",
        "                            if user_data[\"role\"] == 'admin':\n",
        "                                st.session_state.page = \"Dashboard\"\n",
        "                            else:\n",
        "                                st.session_state.page = \"Generator\"\n",
        "\n",
        "                            add_system_log(f\"User '{user_data['username']}' logged in.\", \"üë§\")\n",
        "                            st.rerun()\n",
        "                        else:\n",
        "                            st.error(\"Invalid username or password\")\n",
        "                if st.button(\"Forgot Password?\", type=\"primary\"):\n",
        "                    st.session_state.page = \"Forgot Password\"\n",
        "                    st.rerun()\n",
        "            with tab2:\n",
        "                with st.form(\"signup_form\"):\n",
        "                    st.markdown(\"### Create Your Account\")\n",
        "                    if is_first_user:\n",
        "                        st.info(\"‚ú® You will be the first user! You will be registered as an **Admin**.\")\n",
        "                    new_username = st.text_input(\"Username*\")\n",
        "                    new_password = st.text_input(\"Password*\", type=\"password\")\n",
        "                    new_password_confirm = st.text_input(\"Confirm Password*\", type=\"password\")\n",
        "                    st.markdown(\"---\")\n",
        "                    st.markdown(\"**Security Question (for password reset)**\")\n",
        "                    question = st.selectbox(\"Select a question*\", [\"What was the name of your first pet?\", \"What is your mother's maiden name?\", \"What city were you born in?\", \"What was your first car?\"])\n",
        "                    answer = st.text_input(\"Your Answer*\", type=\"password\")\n",
        "\n",
        "                    signup_button = st.form_submit_button(\"Sign Up\", use_container_width=True)\n",
        "                    if signup_button:\n",
        "                        if not (new_username and new_password and new_password_confirm and answer):\n",
        "                            st.error(\"Please fill out all required fields.\")\n",
        "                        elif new_password != new_password_confirm:\n",
        "                            st.error(\"Passwords do not match.\")\n",
        "                        else:\n",
        "                            role = 'admin' if is_first_user else 'user'\n",
        "                            success = add_user(new_username, new_password, question, answer, role)\n",
        "                            if success:\n",
        "                                add_system_log(f\"New user '{new_username}' registered as '{role}'.\", \"‚ûï\")\n",
        "                                st.success(f\"User '{new_username}' created successfully as {'an Admin' if role == 'admin' else 'a User'}. Please log in.\")\n",
        "                            else:\n",
        "                                st.error(\"Username already exists.\")\n",
        "\n",
        "def show_forgot_password_page():\n",
        "    st.title(\"Reset Password\")\n",
        "    with st.container(border=True):\n",
        "        if \"reset_user\" not in st.session_state: st.session_state.reset_user = None\n",
        "        if \"reset_step\" not in st.session_state: st.session_state.reset_step = 1\n",
        "\n",
        "        if st.session_state.reset_step == 1:\n",
        "            with st.form(\"step1_username\"):\n",
        "                username = st.text_input(\"Enter your username\")\n",
        "                submit_user = st.form_submit_button(\"Next\")\n",
        "                if submit_user:\n",
        "                    user_details = get_user_details(username)\n",
        "                    if user_details:\n",
        "                        st.session_state.reset_user = user_details\n",
        "                        st.session_state.reset_step = 2\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Username not found.\")\n",
        "        if st.session_state.reset_step == 2:\n",
        "            st.info(f\"**Security Question:** {st.session_state.reset_user['question']}\")\n",
        "            with st.form(\"step2_answer\"):\n",
        "                answer = st.text_input(\"Your Answer\", type=\"password\")\n",
        "                submit_answer = st.form_submit_button(\"Verify Answer\")\n",
        "                if submit_answer:\n",
        "                    if check_hash(answer, st.session_state.reset_user['answer_hash']):\n",
        "                        st.session_state.reset_step = 3\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Incorrect answer.\")\n",
        "        if st.session_state.reset_step == 3:\n",
        "            st.success(\"Verification successful!\")\n",
        "            with st.form(\"step3_new_password\"):\n",
        "                new_password = st.text_input(\"New Password\", type=\"password\")\n",
        "                confirm_new_password = st.text_input(\"Confirm New Password\", type=\"password\")\n",
        "                submit_pass = st.form_submit_button(\"Reset Password\")\n",
        "                if submit_pass:\n",
        "                    if not new_password or new_password != confirm_new_password:\n",
        "                        st.error(\"Passwords do not match or are empty.\")\n",
        "                    else:\n",
        "                        update_user_password(st.session_state.reset_user['username'], new_password)\n",
        "                        add_system_log(f\"User '{st.session_state.reset_user['username']}' reset password.\", \"üîë\")\n",
        "                        st.success(\"Password reset successfully! You can now log in.\")\n",
        "                        st.session_state.reset_step = 1\n",
        "                        st.session_state.reset_user = None\n",
        "                        st.session_state.page = \"Login\"\n",
        "                        st.rerun()\n",
        "    if st.button(\"‚Üê Back to Login\"):\n",
        "        st.session_state.page = \"Login\"\n",
        "        st.session_state.reset_step = 1\n",
        "        st.session_state.reset_user = None\n",
        "        st.rerun()\n",
        "\n",
        "def preload_selected_model():\n",
        "    if 'gen_model_key' in st.session_state and st.session_state.gen_model_key:\n",
        "        print(f\"Pre-loading model: {st.session_state.gen_model_key}\")\n",
        "        get_model_and_tokenizer(st.session_state.gen_model_key)\n",
        "\n",
        "def show_generator_page():\n",
        "    st.title(\"ü§ñ Code Generator\")\n",
        "    model_keys = list(MODELS.keys())\n",
        "    selected_model = st.selectbox(\n",
        "        \"Select AI Model\",\n",
        "        model_keys,\n",
        "        key='gen_model_key',\n",
        "        on_change=preload_selected_model\n",
        "    )\n",
        "\n",
        "    if 'loaded_model' not in st.session_state or st.session_state.loaded_model is None:\n",
        "        preload_selected_model()\n",
        "\n",
        "    chat_container = st.container(height=400, border=True)\n",
        "    with chat_container:\n",
        "        for entry in st.session_state.chat_history:\n",
        "            with st.chat_message(entry[\"role\"]):\n",
        "                st.markdown(entry[\"content\"])\n",
        "    prompt = st.text_area(\"Your prompt:\", key=\"prompt_input\", height=100)\n",
        "    col1, col2, col3 = st.columns([2, 1, 1])\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"Generate Code üöÄ\", use_container_width=True, type=\"primary\"):\n",
        "            if prompt:\n",
        "                st.session_state.chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "                with chat_container:\n",
        "                    with st.chat_message(\"user\"):\n",
        "                        st.markdown(prompt)\n",
        "                    with st.chat_message(\"assistant\"):\n",
        "                         message_placeholder = st.empty()\n",
        "\n",
        "                with st.spinner(f\"CodeGenie is thinking with {selected_model}...\"):\n",
        "                    start_time = time.time()\n",
        "                    try:\n",
        "                        response, complexity_score = generate_code(prompt, selected_model)\n",
        "                    except Exception as e:\n",
        "                        response, complexity_score = f\"Error: {str(e)}\", 0\n",
        "                    end_time = time.time()\n",
        "                    latency = end_time - start_time\n",
        "\n",
        "                log_user_activity(st.session_state.username, prompt, selected_model, \"Python\", latency, complexity_score)\n",
        "                message_placeholder.markdown(response)\n",
        "                st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "                if not response.startswith(\"Error:\"):\n",
        "                    st.session_state.last_output = response\n",
        "                st.rerun()\n",
        "            else:\n",
        "                st.warning(\"Please enter a prompt.\")\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"üìã Copy Last Output\", use_container_width=True):\n",
        "            if st.session_state.last_output:\n",
        "                st.components.v1.html(f\"<script>navigator.clipboard.writeText({repr(st.session_state.last_output)});</script>\", height=0)\n",
        "                st.toast(\"Output copied to clipboard!\")\n",
        "            else:\n",
        "                st.toast(\"No output to copy yet.\")\n",
        "    with col3:\n",
        "        if st.button(\"üóëÔ∏è Clear History\", use_container_width=True):\n",
        "            st.session_state.chat_history = []\n",
        "            st.session_state.last_output = \"\"\n",
        "            st.session_state.explanation = \"\"\n",
        "            st.session_state.ast_graph = None\n",
        "            st.rerun()\n",
        "\n",
        "    if 'last_activity_id' in st.session_state and st.session_state.last_activity_id is not None:\n",
        "        st.markdown(\"---\")\n",
        "        with st.form(key=\"feedback_form_gen\"):\n",
        "            st.subheader(\"Was this response helpful?\")\n",
        "            rating = st.radio(\n",
        "                \"Rate this response:\",\n",
        "                options=[1, 2, 3, 4, 5],\n",
        "                format_func=lambda x: \"‚≠ê\" * x,\n",
        "                horizontal=True\n",
        "            )\n",
        "            comment = st.text_area(\"Additional feedback (optional):\")\n",
        "\n",
        "            if st.form_submit_button(\"Submit Feedback\"):\n",
        "                try:\n",
        "                    update_feedback_score(st.session_state.last_activity_id, rating, comment)\n",
        "                    st.success(\"Thank you for your feedback!\")\n",
        "                    st.session_state.last_activity_id = None\n",
        "                    st.rerun()\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Failed to submit feedback: {e}\")\n",
        "\n",
        "def preload_explainer_model():\n",
        "    if 'exp_model_key' in st.session_state and st.session_state.exp_model_key:\n",
        "        print(f\"Pre-loading explainer model: {st.session_state.exp_model_key}\")\n",
        "        get_model_and_tokenizer(st.session_state.exp_model_key)\n",
        "\n",
        "def show_explainer_page():\n",
        "    st.title(\"üî¨ Code Explainer & AST Visualizer\")\n",
        "    lang = st.selectbox(\"Select Language\", [\"Python\", \"JavaScript\", \"SQL\"])\n",
        "    code = st.text_area(\"Paste your code here:\", height=250)\n",
        "    model_keys = list(MODELS.keys())\n",
        "    explainer_model_name = st.selectbox(\n",
        "        \"Select Explainer Model\",\n",
        "        model_keys,\n",
        "        index=0,\n",
        "        key='exp_model_key',\n",
        "        on_change=preload_explainer_model\n",
        "    )\n",
        "\n",
        "    if 'loaded_model' not in st.session_state or st.session_state.loaded_model is None:\n",
        "        preload_explainer_model()\n",
        "\n",
        "    if st.button(\"Explain & Visualize\", type=\"primary\"):\n",
        "        if not code:\n",
        "            st.warning(\"Please paste some code to explain.\")\n",
        "            st.session_state.explanation = \"\"\n",
        "            st.session_state.ast_graph = None\n",
        "            return\n",
        "\n",
        "        st.session_state.explanation = \"\"\n",
        "        st.session_state.ast_graph = None\n",
        "\n",
        "        with st.spinner(f\"Generating explanation with {explainer_model_name}...\"):\n",
        "            explain_prompt = f\"Explain the following {lang} code. Describe what it does, step by step. Provide the explanation in markdown format, using code blocks for the code.\\n\\n```\\n{code}\\n```\"\n",
        "            start_time = time.time()\n",
        "            try:\n",
        "                explanation, complexity_score = query_hf_model(explain_prompt, explainer_model_name)\n",
        "            except Exception as e:\n",
        "                explanation, complexity_score = f\"Error: {str(e)}\", 0\n",
        "            end_time = time.time()\n",
        "            latency = end_time - start_time\n",
        "            log_user_activity(st.session_state.username, code, explainer_model_name, lang, latency, complexity_score)\n",
        "            st.session_state.explanation = explanation\n",
        "\n",
        "        if lang == \"Python\":\n",
        "            visualizer = ASTVisualizer()\n",
        "            graph = visualizer.get_graph(code)\n",
        "            if graph:\n",
        "                st.session_state.ast_graph = graph\n",
        "\n",
        "        st.session_state.last_output = \"Explainer Run\"\n",
        "\n",
        "    if st.session_state.explanation:\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.subheader(\"AI Explanation\")\n",
        "            st.markdown(st.session_state.explanation)\n",
        "        with col2:\n",
        "            st.subheader(\"Abstract Syntax Tree (AST)\")\n",
        "            if st.session_state.ast_graph:\n",
        "                st.graphviz_chart(st.session_state.ast_graph)\n",
        "            elif lang == \"Python\":\n",
        "                 st.error(\"Could not generate AST for this Python code.\")\n",
        "            else:\n",
        "                st.info(f\"AST visualization is only available for Python.\")\n",
        "\n",
        "    if 'last_activity_id' in st.session_state and st.session_state.last_activity_id is not None and st.session_state.last_output == \"Explainer Run\":\n",
        "        st.markdown(\"---\")\n",
        "        with st.form(key=\"feedback_form_exp\"):\n",
        "            st.subheader(\"Was this explanation helpful?\")\n",
        "            rating = st.radio(\n",
        "                \"Rate this response:\",\n",
        "                options=[1, 2, 3, 4, 5],\n",
        "                format_func=lambda x: \"‚≠ê\" * x,\n",
        "                horizontal=True\n",
        "            )\n",
        "            comment = st.text_area(\"Additional feedback (optional):\")\n",
        "\n",
        "            if st.form_submit_button(\"Submit Feedback\"):\n",
        "                try:\n",
        "                    update_feedback_score(st.session_state.last_activity_id, rating, comment)\n",
        "                    st.success(\"Thank you for your feedback!\")\n",
        "                    st.session_state.last_activity_id = None\n",
        "                    st.rerun()\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Failed to submit feedback: {e}\")\n",
        "\n",
        "\n",
        "# --- 9. USER PROFILE PAGE ---\n",
        "\n",
        "def show_profile_page():\n",
        "    st.title(f\"Profile: {st.session_state.username}\")\n",
        "    st.info(f\"**Username:** `{st.session_state.username}`\\n\\n**Role:** `{st.session_state.role}`\")\n",
        "    st.subheader(\"Change Password\")\n",
        "    with st.form(\"change_password_form\"):\n",
        "        current_password = st.text_input(\"Current Password\", type=\"password\")\n",
        "        new_password = st.text_input(\"New Password\", type=\"password\")\n",
        "        confirm_new_password = st.text_input(\"Confirm New Password\", type=\"password\")\n",
        "        submit_change = st.form_submit_button(\"Update Password\")\n",
        "        if submit_change:\n",
        "            user_data = verify_user(st.session_state.username, current_password)\n",
        "            if not user_data:\n",
        "                st.error(\"Incorrect current password.\")\n",
        "            elif not new_password or new_password != confirm_new_password:\n",
        "                st.error(\"New passwords do not match or are empty.\")\n",
        "            else:\n",
        "                update_user_password(st.session_state.username, new_password)\n",
        "                add_system_log(f\"User '{st.session_state.username}' changed password.\", \"üîë\")\n",
        "                st.success(\"Password updated successfully!\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"Recent Activity History\")\n",
        "    history_df = get_user_history(st.session_state.username)\n",
        "    if not history_df.empty:\n",
        "        st.dataframe(history_df, use_container_width=True, hide_index=True)\n",
        "    else:\n",
        "        st.info(\"No activity logged yet.\")\n",
        "\n",
        "# --- 10. FUTURISTIC ADMIN DASHBOARD ---\n",
        "\n",
        "def get_gpu_stats():\n",
        "    \"\"\"Gets GPU stats from torch.cuda.\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return \"N/A (CPU)\", 0, 0, \"N/A\", \"N/A\"\n",
        "\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    total_mem = torch.cuda.get_device_properties(0).total_memory\n",
        "    reserved_mem = torch.cuda.memory_reserved(0)\n",
        "    alloc_mem = torch.cuda.memory_allocated(0)\n",
        "    free_mem = total_mem - reserved_mem\n",
        "\n",
        "    used_mem = total_mem - free_mem\n",
        "    util = (used_mem / total_mem) * 100\n",
        "\n",
        "    return gpu_name, total_mem / 1e9, used_mem / 1e9, f\"{util:.1f}%\", torch.version.cuda\n",
        "\n",
        "def get_system_uptime():\n",
        "    \"\"\"Gets system uptime using psutil.\"\"\"\n",
        "    try:\n",
        "        boot_time = psutil.boot_time()\n",
        "        uptime_seconds = time.time() - boot_time\n",
        "        uptime = str(timedelta(seconds=int(uptime_seconds)))\n",
        "        return uptime\n",
        "    except Exception:\n",
        "        return \"N/A\"\n",
        "\n",
        "def show_admin_dashboard_page():\n",
        "    if st.session_state.role != 'admin':\n",
        "        st.error(\"You do not have permission to view this page.\")\n",
        "        return\n",
        "\n",
        "    # --- Cyberpunk CSS ---\n",
        "    st.markdown(\"\"\"\n",
        "        <style>\n",
        "            .stApp { background-color: #0F111A; }\n",
        "            h1 {\n",
        "                color: #00F0FF;\n",
        "                text-shadow: 0 0 10px #00F0FF, 0 0 20px #00F0FF;\n",
        "                font-family: 'Courier New', Courier, monospace;\n",
        "            }\n",
        "            h2, h3 {\n",
        "                color: #FF00FF;\n",
        "                text-shadow: 0 0 5px #FF00FF;\n",
        "                font-family: 'Courier New', Courier, monospace;\n",
        "                border-bottom: 1px solid #FF00FF;\n",
        "                padding-bottom: 5px;\n",
        "            }\n",
        "            .glowing-card {\n",
        "                padding: 18px; border-radius: 10px; border: 1px solid #00F0FF;\n",
        "                box-shadow: 0 0 15px #00F0FF; background-color: #1A1C2A; margin-bottom: 10px;\n",
        "            }\n",
        "            .glowing-card-magenta { border: 1px solid #FF00FF; box-shadow: 0 0 15px #FF00FF; }\n",
        "            .glowing-card div[data-testid=\"stMetricLabel\"] {\n",
        "                color: #00F0FF; font-size: 1.1em; font-family: 'Courier New', Courier, monospace;\n",
        "            }\n",
        "            .glowing-card div[data-testid=\"stMetricValue\"] {\n",
        "                color: #FFFFFF; font-size: 2.5em; font-family: 'Courier New', Courier, monospace;\n",
        "            }\n",
        "            .log-entry {\n",
        "                font-family: 'IBM Plex Mono', monospace; font-size: 0.9em; color: #E0E0E0;\n",
        "                border-bottom: 1px solid #333; padding-bottom: 5px; margin-bottom: 5px;\n",
        "            }\n",
        "            .health-badge {\n",
        "                display: inline-block; padding: 4px 10px; border-radius: 15px;\n",
        "                font-size: 0.9em; font-family: 'Courier New', Courier, monospace; margin-right: 10px;\n",
        "            }\n",
        "            .health-green { background-color: #004D00; color: #39FF14; border: 1px solid #39FF14; }\n",
        "            .health-red { background-color: #4D0000; color: #FF073A; border: 1px solid #FF073A; }\n",
        "            .health-yellow { background-color: #4D4D00; color: #FFFF33; border: 1px solid #FFFF33; }\n",
        "        </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # --- 1. Cyberpunk Boot Animation ---\n",
        "    if not st.session_state.admin_boot_animation_done:\n",
        "        st.title(\"CodeGenie Control Grid\")\n",
        "        boot_placeholder = st.empty()\n",
        "        boot_messages = [\n",
        "            \"‚öôÔ∏è Initializing Neural Interface...\",\n",
        "            \"üîå Syncing model cores...\",\n",
        "            \"üåê Activating CodeGenie Control Grid...\",\n",
        "            \"‚úÖ System Online. Welcome, Admin.\"\n",
        "        ]\n",
        "        message_so_far = \"\"\n",
        "        for msg in boot_messages:\n",
        "            message_so_far += f\"<h3 style='font-family: Courier New; color: #39FF14; text-shadow: 0 0 10px #39FF14;'>{msg}</h3>\"\n",
        "            boot_placeholder.markdown(message_so_far, unsafe_allow_html=True)\n",
        "            time.sleep(0.5)\n",
        "        time.sleep(1)\n",
        "        st.session_state.admin_boot_animation_done = True\n",
        "        add_system_log(\"Admin Dashboard Initialized\", \"üöÄ\")\n",
        "        st.rerun()\n",
        "\n",
        "    # --- Main Dashboard ---\n",
        "    st.title(\"üëë Admin Dashboard\")\n",
        "    st_autorefresh(interval=10000, key=\"admin_refresh\")\n",
        "\n",
        "    gpu_name, total_mem, used_mem, util, cuda_v = get_gpu_stats()\n",
        "\n",
        "    if total_mem > 0 and (used_mem / total_mem) > 0.9:\n",
        "        st.error(f\"üö® VRAM usage is critical: {util}! System may be unstable.\", icon=\"üö®\")\n",
        "\n",
        "    # --- NEW: Replaced Model Monitor with Key Stats ---\n",
        "    dash_col1, dash_col2 = st.columns(2)\n",
        "    with dash_col1:\n",
        "        st.subheader(\"üìä Key Usage Statistics\")\n",
        "        total_users = get_total_users()\n",
        "        total_queries = get_total_queries()\n",
        "        avg_latency = get_average_latency()\n",
        "        feedback_rate, feedback_delta = get_positive_feedback_rate()\n",
        "\n",
        "        c1, c2 = st.columns(2)\n",
        "        with c1:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"glowing-card\">\n",
        "                <div data-testid=\"stMetricLabel\">Total Users</div>\n",
        "                <div data-testid=\"stMetricValue\" style=\"font-size: 2em;\">{total_users}</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"glowing-card glowing-card-magenta\">\n",
        "                <div data-testid=\"stMetricLabel\">Avg. Response Time</div>\n",
        "                <div data-testid=\"stMetricValue\" style=\"font-size: 2em; color: #FF00FF;\">{avg_latency}s</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "        with c2:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"glowing-card\">\n",
        "                <div data-testid=\"stMetricLabel\">Total Queries</div>\n",
        "                <div data-testid=\"stMetricValue\" style=\"font-size: 2em;\">{total_queries}</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"glowing-card glowing-card-magenta\">\n",
        "                <div data-testid=\"stMetricLabel\">Positive Feedback</div>\n",
        "                <div data-testid=\"stMetricValue\" style=\"font-size: 2em; color: #FF00FF;\">{feedback_rate}</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with dash_col2:\n",
        "        st.subheader(\"üì° Live Network & Query Ticker\")\n",
        "\n",
        "        if 'network_history' not in st.session_state: st.session_state.network_history = []\n",
        "        new_traffic = np.random.randint(50, 500)\n",
        "        st.session_state.network_history.append({\"time\": datetime.now(), \"Traffic (MB/s)\": new_traffic})\n",
        "        st.session_state.network_history = st.session_state.network_history[-50:]\n",
        "\n",
        "        df_net = pd.DataFrame(st.session_state.network_history)\n",
        "        fig_net = go.Figure()\n",
        "        fig_net.add_trace(go.Scatter(x=df_net['time'], y=df_net['Traffic (MB/s)'], mode='lines',\n",
        "                                     line=dict(color='#39FF14', width=2), fill='tozeroy',\n",
        "                                     fillcolor='rgba(57, 255, 20, 0.3)'))\n",
        "        fig_net.update_layout(\n",
        "            title=\"Simulated Network I/O\", template=\"plotly_dark\", paper_bgcolor='rgba(0,0,0,0)',\n",
        "            plot_bgcolor='rgba(26, 28, 42, 0.8)', font_color=\"#39FF14\", height=200,\n",
        "            xaxis=dict(showgrid=False, zeroline=False), yaxis=dict(gridcolor='#444', zeroline=False)\n",
        "        )\n",
        "        st.plotly_chart(fig_net, use_container_width=True, config={'displayModeBar': False})\n",
        "\n",
        "        st.markdown(\"<h6>Live Query Ticker</h6>\", unsafe_allow_html=True)\n",
        "        ticker_logs = get_full_history().head(5) # Get last 5 queries\n",
        "        ticker_placeholder = st.empty()\n",
        "        log_html = \"\"\n",
        "        for _, row in ticker_logs.iterrows():\n",
        "            log_html += f\"<div class='log-entry'>üõ∞Ô∏è {row['timestamp']} - User ID {row['user_id']} queried {row['model_name']}</div>\"\n",
        "        ticker_placeholder.markdown(f\"\"\"\n",
        "            <div style=\"height: 150px; background-color: #0A0C12; border-radius: 5px; padding: 10px; overflow-y: scroll; border: 1px solid #444;\">\n",
        "                {log_html if not ticker_logs.empty else \"<div class='log-entry'>...Awaiting user activity...</div>\"}\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # --- System Health & VRAM Graph (Moved to bottom) ---\n",
        "    col1, col2 = st.columns([1, 2])\n",
        "    with col1:\n",
        "        st.subheader(\"System Health\")\n",
        "        st.markdown(\"<h5>Health Check</h5>\", unsafe_allow_html=True)\n",
        "        if torch.cuda.is_available():\n",
        "            st.markdown('<span class=\"health-badge health-green\">üü¢ CUDA: OK</span>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown('<span class=\"health-badge health-red\">üî¥ CUDA: Fail</span>', unsafe_allow_html=True)\n",
        "        if HF_TOKEN and HF_TOKEN.startswith(\"hf_\"):\n",
        "            st.markdown('<span class=\"health-badge health-green\">üü¢ HF Token: OK</span>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown('<span class=\"health-badge health-red\">üî¥ HF Token: Missing</span>', unsafe_allow_html=True)\n",
        "        if NGROK_TOKEN:\n",
        "            st.markdown('<span class=\"health-badge health-green\">üü¢ Ngrok Token: OK</span>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown('<span class=\"health-badge health-red\">üî¥ Ngrok Token: Missing</span>', unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(f\"\"\"\n",
        "            <div class=\"glowing-card\">\n",
        "                <div data-testid=\"stMetricLabel\">GPU</div>\n",
        "                <div data-testid=\"stMetricValue\" style=\"font-size: 1.5em; color: #00F0FF;\">{gpu_name}</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "        st.markdown(f\"\"\"\n",
        "            <div class=\"glowing-card\">\n",
        "                <div data-testid=\"stMetricLabel\">System Uptime</div>\n",
        "                <div data-testid=\"stMetricValue\" style=\"font-size: 1.5em;\">{get_system_uptime()}</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Live VRAM\")\n",
        "        if 'gpu_history' not in st.session_state: st.session_state.gpu_history = []\n",
        "        st.session_state.gpu_history.append({\"time\": datetime.now(), \"VRAM (GB)\": used_mem, \"Total (GB)\": total_mem})\n",
        "        st.session_state.gpu_history = st.session_state.gpu_history[-50:]\n",
        "\n",
        "        if st.session_state.gpu_history and total_mem > 0:\n",
        "            df = pd.DataFrame(st.session_state.gpu_history)\n",
        "            fig = px.area(df, x=\"time\", y=\"VRAM (GB)\", title=\"VRAM Usage Over Time\", range_y=[0, total_mem])\n",
        "            fig.update_layout(template=\"plotly_dark\", paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color=\"#00F0FF\", xaxis=dict(showgrid=False), yaxis=dict(gridcolor='#444'))\n",
        "            fig.update_traces(line=dict(color=\"#FF00FF\"))\n",
        "            st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})\n",
        "        else:\n",
        "            st.info(\"No GPU detected. VRAM chart disabled.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # --- Logs, Analytics, and Config in Tabs ---\n",
        "    log_tab, analytics_tab, config_tab = st.tabs([\"[ Terminal Logs ]\", \"[ User Analytics ]\", \"[ System Configuration ]\"])\n",
        "\n",
        "    with log_tab:\n",
        "        st.subheader(\"Live System Logs\")\n",
        "        st.markdown(f\"\"\"\n",
        "            <div style=\"height: 300px; background-color: #0A0C12; border-radius: 5px; padding: 10px; overflow-y: scroll; border: 1px solid #444;\">\n",
        "                {''.join(f'<div class=\"log-entry\">{log}</div>' for log in st.session_state.system_logs)}\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with analytics_tab:\n",
        "        st.subheader(\"User Feedback & Usage\")\n",
        "        trending_queries_df = get_trending_queries()\n",
        "        lang_usage_df = get_language_usage()\n",
        "\n",
        "        colA, colB = st.columns(2)\n",
        "        with colA:\n",
        "            st.subheader(\"Trending Queries (Top 5)\")\n",
        "            if not trending_queries_df.empty:\n",
        "                fig_trends = px.bar(trending_queries_df, x='Count', y='Query', title=\"Trending Queries\", orientation='h')\n",
        "                fig_trends.update_layout(template=\"plotly_dark\", paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color=\"#FF00FF\")\n",
        "                st.plotly_chart(fig_trends, use_container_width=True)\n",
        "            else:\n",
        "                st.info(\"No queries logged yet.\")\n",
        "        with colB:\n",
        "            st.subheader(\"Language Usage Breakdown\")\n",
        "            if not lang_usage_df.empty and lang_usage_df['Count'].sum() > 0:\n",
        "                fig_lang = px.bar(lang_usage_df, x='Language', y='Count', title='Language Usage', color='Language')\n",
        "                fig_lang.update_layout(template=\"plotly_dark\", paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color=\"#00F0FF\")\n",
        "                st.plotly_chart(fig_lang, use_container_width=True)\n",
        "            else:\n",
        "                 st.info(\"No language usage data recorded yet.\")\n",
        "\n",
        "    with config_tab:\n",
        "        st.subheader(\"üîê Token Manager\")\n",
        "        st.session_state.reveal_keys = st.checkbox(\"üëÅÔ∏è Reveal Keys\", value=st.session_state.reveal_keys)\n",
        "        key_type = \"text\" if st.session_state.reveal_keys else \"password\"\n",
        "        st.text_input(\"HF_TOKEN\", value=HF_TOKEN, type=key_type, disabled=True)\n",
        "        st.text_input(\"JWT_SECRET_KEY\", value=JWT_SECRET, type=key_type, disabled=True)\n",
        "        st.text_input(\"NGROK_TOKEN\", value=NGROK_TOKEN, type=key_type, disabled=True)\n",
        "        st.info(\"Tokens are loaded from Colab Secrets and cannot be edited here.\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"üß™ Experimental Controls\")\n",
        "        st.session_state.exp_mixed_precision = st.toggle(\"Mixed Precision (AMP)\", value=st.session_state.exp_mixed_precision, help=\"Use torch.cuda.amp.autocast for inference. (Default: On)\")\n",
        "        st.session_state.exp_torch_compile = st.toggle(\"Torch.compile() (Experimental)\", value=st.session_state.exp_torch_compile, help=\"Use torch.compile() for potential speedup. Requires restart. (Default: Off)\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"üß† Model Hot-Swap & Memory\")\n",
        "        st.markdown(\"<h6>Model Hot-Swap</h6>\", unsafe_allow_html=True)\n",
        "        m1, m2, m3 = st.columns(3)\n",
        "        if m1.button(\"Load Gemma-2B\", use_container_width=True):\n",
        "            get_model_and_tokenizer(\"Gemma-2B-IT\")\n",
        "            st.rerun()\n",
        "        if m2.button(\"Load DeepSeek\", use_container_width=True):\n",
        "            get_model_and_tokenizer(\"DeepSeek-Coder-1.3B\")\n",
        "            st.rerun()\n",
        "        if m3.button(\"Load Phi-2\", use_container_width=True):\n",
        "            get_model_and_tokenizer(\"Phi-2\")\n",
        "            st.rerun()\n",
        "\n",
        "        st.markdown(\"<h6>Memory Controls</h6>\", unsafe_allow_html=True)\n",
        "        c1, c2 = st.columns(2)\n",
        "        if c1.button(\"‚ôªÔ∏è Clear VRAM Cache\", use_container_width=True):\n",
        "            with st.spinner(\"Clearing cache...\"):\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "                add_system_log(\"VRAM Cache Cleared\", \"üßπ\")\n",
        "                st.toast(\"VRAM Cache Cleared!\")\n",
        "        if c2.button(\"üîÑ Reload Current Model\", use_container_width=True):\n",
        "            if 'loaded_model_name' in st.session_state and st.session_state.loaded_model_name:\n",
        "                add_system_log(f\"Reloading model: {st.session_state.loaded_model_name}\", \"üîÑ\")\n",
        "                current_model_key = [k for k, v in MODELS.items() if v == st.session_state.loaded_model_name][0]\n",
        "                del st.session_state.loaded_model_name\n",
        "                if 'loaded_model' in st.session_state: del st.session_state.loaded_model\n",
        "                if 'loaded_tokenizer' in st.session_state: del st.session_state.loaded_tokenizer\n",
        "                get_model_and_tokenizer(current_model_key) # This will force a reload\n",
        "                st.toast(\"Model reloaded!\")\n",
        "                st.rerun()\n",
        "            else:\n",
        "                st.toast(\"No model loaded to reload.\")\n",
        "\n",
        "\n",
        "def show_admin_users_page():\n",
        "    if st.session_state.role != 'admin':\n",
        "        st.error(\"You do not have permission to view this page.\")\n",
        "        return\n",
        "    st.title(\"üëë Admin: User Management\")\n",
        "\n",
        "    tab_users, tab_history, tab_feedback = st.tabs([\"User List\", \"Full Query History\", \"Full Feedback Log\"])\n",
        "\n",
        "    with tab_users:\n",
        "        st.subheader(\"All Registered Users\")\n",
        "        users = get_all_users()\n",
        "        if users:\n",
        "            df_data = [{\"ID\": user[0], \"Username\": user[1], \"Role\": user[2]} for user in users]\n",
        "            st.dataframe(pd.DataFrame(df_data), use_container_width=True, hide_index=True)\n",
        "        else:\n",
        "            st.info(\"No users found (except you).\")\n",
        "\n",
        "    with tab_history:\n",
        "        st.subheader(\"Full Query History (Last 20)\")\n",
        "        st.dataframe(get_full_history(), use_container_width=True)\n",
        "\n",
        "    with tab_feedback:\n",
        "        st.subheader(\"Full Feedback Log (Last 10)\")\n",
        "        feedback_data = get_full_feedback()\n",
        "        if not feedback_data.empty:\n",
        "            st.dataframe(feedback_data, use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"No feedback has been submitted yet.\")\n",
        "\n",
        "\n",
        "# --- 8. USER-FACING PAGES (Unchanged) ---\n",
        "\n",
        "def show_profile_page():\n",
        "    st.title(f\"Profile: {st.session_state.username}\")\n",
        "    st.info(f\"**Username:** `{st.session_state.username}`\\n\\n**Role:** `{st.session_state.role}`\")\n",
        "    st.subheader(\"Change Password\")\n",
        "    with st.form(\"change_password_form\"):\n",
        "        current_password = st.text_input(\"Current Password\", type=\"password\")\n",
        "        new_password = st.text_input(\"New Password\", type=\"password\")\n",
        "        confirm_new_password = st.text_input(\"Confirm New Password\", type=\"password\")\n",
        "        submit_change = st.form_submit_button(\"Update Password\")\n",
        "        if submit_change:\n",
        "            user_data = verify_user(st.session_state.username, current_password)\n",
        "            if not user_data:\n",
        "                st.error(\"Incorrect current password.\")\n",
        "            elif not new_password or new_password != confirm_new_password:\n",
        "                st.error(\"New passwords do not match or are empty.\")\n",
        "            else:\n",
        "                update_user_password(st.session_state.username, new_password)\n",
        "                add_system_log(f\"User '{st.session_state.username}' changed password.\", \"üîë\")\n",
        "                st.success(\"Password updated successfully!\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"Recent Activity History\")\n",
        "    history_df = get_user_history(st.session_state.username)\n",
        "    if not history_df.empty:\n",
        "        st.dataframe(history_df, use_container_width=True, hide_index=True)\n",
        "    else:\n",
        "        st.info(\"No activity logged yet.\")\n",
        "\n",
        "def preload_selected_model():\n",
        "    if 'gen_model_key' in st.session_state and st.session_state.gen_model_key:\n",
        "        print(f\"Pre-loading model: {st.session_state.gen_model_key}\")\n",
        "        get_model_and_tokenizer(st.session_state.gen_model_key)\n",
        "\n",
        "def show_generator_page():\n",
        "    st.title(\"ü§ñ Code Generator\")\n",
        "    model_keys = list(MODELS.keys())\n",
        "    selected_model = st.selectbox(\n",
        "        \"Select AI Model\",\n",
        "        model_keys,\n",
        "        key='gen_model_key',\n",
        "        on_change=preload_selected_model\n",
        "    )\n",
        "\n",
        "    if 'loaded_model' not in st.session_state or st.session_state.loaded_model is None:\n",
        "        preload_selected_model()\n",
        "\n",
        "    chat_container = st.container(height=400, border=True)\n",
        "    with chat_container:\n",
        "        for entry in st.session_state.chat_history:\n",
        "            with st.chat_message(entry[\"role\"]):\n",
        "                st.markdown(entry[\"content\"])\n",
        "    prompt = st.text_area(\"Your prompt:\", key=\"prompt_input\", height=100)\n",
        "    col1, col2, col3 = st.columns([2, 1, 1])\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"Generate Code üöÄ\", use_container_width=True, type=\"primary\"):\n",
        "            if prompt:\n",
        "                st.session_state.chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "                with chat_container:\n",
        "                    with st.chat_message(\"user\"):\n",
        "                        st.markdown(prompt)\n",
        "                    with st.chat_message(\"assistant\"):\n",
        "                         message_placeholder = st.empty()\n",
        "\n",
        "                with st.spinner(f\"CodeGenie is thinking with {selected_model}...\"):\n",
        "                    start_time = time.time()\n",
        "                    try:\n",
        "                        response = generate_code(prompt, selected_model)\n",
        "                    except Exception as e:\n",
        "                        response = f\"Error: {str(e)}\"\n",
        "                    end_time = time.time()\n",
        "                    latency = end_time - start_time\n",
        "\n",
        "                log_user_activity(st.session_state.username, prompt, selected_model, \"Python\", latency)\n",
        "                message_placeholder.markdown(response)\n",
        "                st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "                if not response.startswith(\"Error:\"):\n",
        "                    st.session_state.last_output = response\n",
        "                st.rerun()\n",
        "            else:\n",
        "                st.warning(\"Please enter a prompt.\")\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"üìã Copy Last Output\", use_container_width=True):\n",
        "            if st.session_state.last_output:\n",
        "                st.components.v1.html(f\"<script>navigator.clipboard.writeText({repr(st.session_state.last_output)});</script>\", height=0)\n",
        "                st.toast(\"Output copied to clipboard!\")\n",
        "            else:\n",
        "                st.toast(\"No output to copy yet.\")\n",
        "    with col3:\n",
        "        if st.button(\"üóëÔ∏è Clear History\", use_container_width=True):\n",
        "            st.session_state.chat_history = []\n",
        "            st.session_state.last_output = \"\"\n",
        "            st.session_state.explanation = \"\"\n",
        "            st.session_state.ast_graph = None\n",
        "            st.rerun()\n",
        "\n",
        "    if 'last_activity_id' in st.session_state and st.session_state.last_activity_id is not None:\n",
        "        st.markdown(\"---\")\n",
        "        with st.form(key=\"feedback_form_gen\"):\n",
        "            st.subheader(\"Was this response helpful?\")\n",
        "            rating = st.radio(\n",
        "                \"Rate this response:\",\n",
        "                options=[1, 2, 3, 4, 5],\n",
        "                format_func=lambda x: \"‚≠ê\" * x,\n",
        "                horizontal=True\n",
        "            )\n",
        "            comment = st.text_area(\"Additional feedback (optional):\")\n",
        "\n",
        "            if st.form_submit_button(\"Submit Feedback\"):\n",
        "                try:\n",
        "                    update_feedback_score(st.session_state.last_activity_id, rating, comment)\n",
        "                    st.success(\"Thank you for your feedback!\")\n",
        "                    st.session_state.last_activity_id = None\n",
        "                    st.rerun()\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Failed to submit feedback: {e}\")\n",
        "\n",
        "def preload_explainer_model():\n",
        "    if 'exp_model_key' in st.session_state and st.session_state.exp_model_key:\n",
        "        print(f\"Pre-loading explainer model: {st.session_state.exp_model_key}\")\n",
        "        get_model_and_tokenizer(st.session_state.exp_model_key)\n",
        "\n",
        "def show_explainer_page():\n",
        "    st.title(\"üî¨ Code Explainer & AST Visualizer\")\n",
        "    lang = st.selectbox(\"Select Language\", [\"Python\", \"JavaScript\", \"SQL\"])\n",
        "    code = st.text_area(\"Paste your code here:\", height=250)\n",
        "    model_keys = list(MODELS.keys())\n",
        "    explainer_model_name = st.selectbox(\n",
        "        \"Select Explainer Model\",\n",
        "        model_keys,\n",
        "        index=0,\n",
        "        key='exp_model_key',\n",
        "        on_change=preload_explainer_model\n",
        "    )\n",
        "\n",
        "    if 'loaded_model' not in st.session_state or st.session_state.loaded_model is None:\n",
        "        preload_explainer_model()\n",
        "\n",
        "    if st.button(\"Explain & Visualize\", type=\"primary\"):\n",
        "        if not code:\n",
        "            st.warning(\"Please paste some code to explain.\")\n",
        "            st.session_state.explanation = \"\"\n",
        "            st.session_state.ast_graph = None\n",
        "            return\n",
        "\n",
        "        st.session_state.explanation = \"\"\n",
        "        st.session_state.ast_graph = None\n",
        "\n",
        "        with st.spinner(f\"Generating explanation with {explainer_model_name}...\"):\n",
        "            explain_prompt = f\"Explain the following {lang} code. Describe what it does, step by step. Provide the explanation in markdown format, using code blocks for the code.\\n\\n```\\n{code}\\n```\"\n",
        "            start_time = time.time()\n",
        "            try:\n",
        "                explanation = query_hf_model(explain_prompt, explainer_model_name)\n",
        "            except Exception as e:\n",
        "                explanation = f\"Error: {str(e)}\"\n",
        "            end_time = time.time()\n",
        "            latency = end_time - start_time\n",
        "            log_user_activity(st.session_state.username, code, explainer_model_name, lang, latency)\n",
        "            st.session_state.explanation = explanation\n",
        "\n",
        "        if lang == \"Python\":\n",
        "            visualizer = ASTVisualizer()\n",
        "            graph = visualizer.get_graph(code)\n",
        "            if graph:\n",
        "                st.session_state.ast_graph = graph\n",
        "\n",
        "        st.session_state.last_output = \"Explainer Run\"\n",
        "\n",
        "    if st.session_state.explanation:\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.subheader(\"AI Explanation\")\n",
        "            st.markdown(st.session_state.explanation)\n",
        "        with col2:\n",
        "            st.subheader(\"Abstract Syntax Tree (AST)\")\n",
        "            if st.session_state.ast_graph:\n",
        "                st.graphviz_chart(st.session_state.ast_graph)\n",
        "            elif lang == \"Python\":\n",
        "                 st.error(\"Could not generate AST for this Python code.\")\n",
        "            else:\n",
        "                st.info(f\"AST visualization is only available for Python.\")\n",
        "\n",
        "    if 'last_activity_id' in st.session_state and st.session_state.last_activity_id is not None and st.session_state.last_output == \"Explainer Run\":\n",
        "        st.markdown(\"---\")\n",
        "        with st.form(key=\"feedback_form_exp\"):\n",
        "            st.subheader(\"Was this explanation helpful?\")\n",
        "            rating = st.radio(\n",
        "                \"Rate this response:\",\n",
        "                options=[1, 2, 3, 4, 5],\n",
        "                format_func=lambda x: \"‚≠ê\" * x,\n",
        "                horizontal=True\n",
        "            )\n",
        "            comment = st.text_area(\"Additional feedback (optional):\")\n",
        "\n",
        "            if st.form_submit_button(\"Submit Feedback\"):\n",
        "                try:\n",
        "                    update_feedback_score(st.session_state.last_activity_id, rating, comment)\n",
        "                    st.success(\"Thank you for your feedback!\")\n",
        "                    st.session_state.last_activity_id = None\n",
        "                    st.rerun()\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Failed to submit feedback: {e}\")\n",
        "\n",
        "\n",
        "# --- 10. MAIN APP ROUTER (WITH ROLE-BASED NAVIGATION) ---\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"CodeGenie\", page_icon=\"üßû\", layout=\"wide\")\n",
        "    is_first_user = init_db()\n",
        "    initialize_state()\n",
        "\n",
        "    if st.session_state.token:\n",
        "        payload = verify_jwt(st.session_state.token)\n",
        "        if payload:\n",
        "            st.session_state.logged_in = True\n",
        "            st.session_state.username = payload['sub']\n",
        "            st.session_state.role = payload['role']\n",
        "        else:\n",
        "            for key in list(st.session_state.keys()):\n",
        "                del st.session_state[key]\n",
        "            st.rerun()\n",
        "\n",
        "    if not st.session_state.logged_in:\n",
        "        if st.session_state.page == \"Forgot Password\":\n",
        "            show_forgot_password_page()\n",
        "        else:\n",
        "            show_login_page(is_first_user)\n",
        "    else:\n",
        "        with st.sidebar:\n",
        "            st.title(f\"CodeGenie üßû\")\n",
        "            st.markdown(f\"Welcome, **{st.session_state.username}**!\")\n",
        "            st.markdown(\"---\")\n",
        "            def set_page(page_name):\n",
        "                st.session_state.page = page_name\n",
        "\n",
        "            if st.session_state.role == 'admin':\n",
        "                st.markdown(\"*Admin Tools*\")\n",
        "                st.button(\"Admin Dashboard\", use_container_width=True, type=\"primary\" if st.session_state.page == \"Dashboard\" else \"secondary\", on_click=set_page, args=(\"Dashboard\",))\n",
        "                st.button(\"Manage Users\", use_container_width=True, type=\"primary\" if st.session_state.page == \"Admin\" else \"secondary\", on_click=set_page, args=(\"Admin\",))\n",
        "                st.button(\"My Profile\", use_container_width=True, type=\"primary\" if st.session_state.page == \"Profile\" else \"secondary\", on_click=set_page, args=(\"Profile\",))\n",
        "\n",
        "            else: # If role == 'user'\n",
        "                st.button(\"Code Generator\", use_container_width=True, type=\"primary\" if st.session_state.page == \"Generator\" else \"secondary\", on_click=set_page, args=(\"Generator\",))\n",
        "                st.button(\"Code Explainer\", use_container_width=True, type=\"primary\" if st.session_state.page == \"Explainer\" else \"secondary\", on_click=set_page, args=(\"Explainer\",))\n",
        "                st.button(\"My Profile\", use_container_width=True, type=\"primary\" if st.session_state.page == \"Profile\" else \"secondary\", on_click=set_page, args=(\"Profile\",))\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            if st.button(\"Logout üîí\", use_container_width=True):\n",
        "                add_system_log(f\"User '{st.session_state.username}' logged out.\", \"üëã\")\n",
        "                for key in list(st.session_state.keys()):\n",
        "                    del st.session_state[key]\n",
        "                st.rerun()\n",
        "\n",
        "        if st.session_state.role == 'admin':\n",
        "            if st.session_state.page == \"Dashboard\":\n",
        "                show_admin_dashboard_page()\n",
        "            elif st.session_state.page == \"Admin\":\n",
        "                show_admin_users_page()\n",
        "            elif st.session_state.page == \"Profile\":\n",
        "                show_profile_page()\n",
        "            else:\n",
        "                st.session_state.page = \"Dashboard\"\n",
        "                st.rerun()\n",
        "\n",
        "        else: # If role == 'user'\n",
        "            if st.session_state.page == \"Generator\":\n",
        "                show_generator_page()\n",
        "            elif st.session_state.page == \"Explainer\":\n",
        "                show_explainer_page()\n",
        "            elif st.session_state.page == \"Profile\":\n",
        "                show_profile_page()\n",
        "            else:\n",
        "                st.session_state.page = \"Generator\"\n",
        "                st.rerun()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3fRtslwKgk8",
        "outputId": "08d8d4f0-55e4-4397-8a59-feae0f84b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Launch the App (Final Version)\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import socket\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- Clean up any old ngrok/Streamlit processes ----\n",
        "print(\"üßπ Cleaning up old ngrok and Streamlit processes...\")\n",
        "!pkill -f ngrok 2>/dev/null || echo \"No old ngrok\"\n",
        "!kill -9 $(lsof -t -i:8501) 2>/dev/null || echo \"No old Streamlit\"\n",
        "\n",
        "# ---- Authenticate ngrok ----\n",
        "ngrok.set_auth_token(os.environ['NGROK_TOKEN'])\n",
        "\n",
        "# ---- Helper to wait for Streamlit ----\n",
        "def wait_for_port(host=\"localhost\", port=8501, timeout=90):\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout:\n",
        "        try:\n",
        "            with socket.create_connection((host, port), timeout=2):\n",
        "                return True\n",
        "        except OSError:\n",
        "            time.sleep(1)\n",
        "    return False\n",
        "\n",
        "# ---- Start Streamlit ----\n",
        "print(\"üöÄ Starting Streamlit on port 8501...\")\n",
        "# Start the process and pipe logs to files\n",
        "process = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
        "    stdout=open(\"streamlit.log\", \"w\"),\n",
        "    stderr=open(\"streamlit.err\", \"w\")\n",
        ")\n",
        "\n",
        "# ---- Wait until Streamlit is ready ----\n",
        "print(\"‚è≥ Waiting for Streamlit to start...\")\n",
        "if not wait_for_port():\n",
        "    print(\"‚ùå Streamlit did not start. Check app logs.\")\n",
        "    # Print the error logs if it fails\n",
        "    !echo \"--- STDOUT ---\"\n",
        "    !cat streamlit.log\n",
        "    !echo \"--- STDERR ---\"\n",
        "    !cat streamlit.err\n",
        "else:\n",
        "    # ---- Open ngrok tunnel only after Streamlit is ready ----\n",
        "    print(\"üåê Opening ngrok tunnel...\")\n",
        "    tunnel = ngrok.connect(8501)\n",
        "    print(f\"\\n‚úÖ Your Streamlit app is live!\\nüëâ {tunnel.public_url}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoMgV4mIK4Qn",
        "outputId": "79de23fe-4a97-45f8-dfdc-c0d56afccbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning up old ngrok and Streamlit processes...\n",
            "^C\n",
            "üöÄ Starting Streamlit on port 8501...\n",
            "‚è≥ Waiting for Streamlit to start...\n",
            "üåê Opening ngrok tunnel...\n",
            "\n",
            "‚úÖ Your Streamlit app is live!\n",
            "üëâ https://rosemary-tricuspidate-earlene.ngrok-free.dev\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z2ilSO6uK5ZT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}